{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowl_cascade = cv2.CascadeClassifier('bowl/cascade.xml')\n",
    "MR_cascade = cv2.CascadeClassifier('Mars Rover/cascade2.xml')\n",
    "QC_cascade = cv2.CascadeClassifier('MyHaarcascades/Quadcopter/classifier/cascade.xml')\n",
    "wheel_cascade = cv2.CascadeClassifier('MyHaarcascades/wheel/classifier/cascade.xml')\n",
    "\n",
    "def drawBox(img,bbox):\n",
    "    x, y, w, h = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])\n",
    "    cv2.rectangle(img, (x, y), ((x + w), (y + h)), (255, 0, 255), 3, 3 )\n",
    "    cv2.putText(img, \"Tracking\", (100, 75), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "def moveahead():\n",
    "    return\n",
    "\n",
    "\n",
    "def align():\n",
    "    \n",
    "    moveahead()\n",
    "    return\n",
    "\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    img1= cv2.imread('sample6.jpg')\n",
    "    bowl = bowl_cascade.detectMultiScale(img1, 1.3, 5)\n",
    "    for (x,y,w,h) in bowl:\n",
    "        cv2.rectangle(img1,(x,y),(x+w,y+h),(255,0,255),2)\n",
    "        cv2.putText(img1,'Bowl',(x,y-5),cv2.FONT_HERSHEY_COMPLEX,2,(0,1500),1)\n",
    "        #roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img1[y:y+h, x:x+w] \n",
    "    MR = MR_cascade.detectMultiScale(img1, 1.3, 5)\n",
    "    for (x,y,w,h) in MR:\n",
    "        cv2.rectangle(img1,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        cv2.putText(img1,'MR',(x,y-5),cv2.FONT_HERSHEY_COMPLEX,2,(0,1500),1)\n",
    "        #roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img1[y:y+h, x:x+w]\n",
    "    MR = QC_cascade.detectMultiScale(img1, 1.3, 5)\n",
    "    for (x,y,w,h) in MR:\n",
    "        cv2.rectangle(img1,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        cv2.putText(img1,'QC',(x,y-5),cv2.FONT_HERSHEY_COMPLEX,2,(0,1500),1)\n",
    "        #roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img1[y:y+h, x:x+w]\n",
    "    \n",
    "    MR = wheel_cascade.detectMultiScale(img1, 1.3, 5)\n",
    "    for (x,y,w,h) in MR:\n",
    "        cv2.rectangle(img1,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "        cv2.putText(img1,'Wheel',(x,y-5),cv2.FONT_HERSHEY_COMPLEX,2,(0,1500),1)\n",
    "        #roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img1[y:y+h, x:x+w]\n",
    "\n",
    "    cv2.imshow('img',img1)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are you satisfied with detection (y/n)?n\n"
     ]
    }
   ],
   "source": [
    "def drawBox(img,bbox):\n",
    "    x, y, w, h = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])\n",
    "    cv2.rectangle(img, (x, y), ((x + w), (y + h)), (255, 0, 255), 3, 3 )\n",
    "    cv2.putText(img, \"Tracking\", (100, 75), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "val= input('are you satisfied with detection (y/n)?')\n",
    "tracker = cv2.TrackerMOSSE_create()\n",
    "cap = cv2.VideoCapture(0)\n",
    "if val is 'y':\n",
    "    align()\n",
    "elif val is 'n':\n",
    "    success, frame = cap.read()\n",
    "    bbox = cv2.selectROI(\"Tracking\",frame, False)\n",
    "    tracker.init(frame, bbox)\n",
    "    \n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "        success, bbox = tracker.update(img)\n",
    "\n",
    "        if success:\n",
    "            drawBox(img,bbox)\n",
    "        else:\n",
    "            cv2.putText(img, \"Lost\", (100, 75), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            \n",
    "        cv2.imshow(\"Tracking\", img)\n",
    "        if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
